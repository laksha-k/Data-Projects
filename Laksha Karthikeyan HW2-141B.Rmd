---
title: "STA141B HW 2 - Laksha Karthikeyan"
author: "Laksha Karthikeyan"
date: "2023-05-02"
output:
  pdf_document: default
  html_document: default
---
```{r setup, echo=FALSE}
#knitr::opts_chunk$set(echo=TRUE)
knitr::read_chunk('HW2-dataframe-141B.R')
```

```{r}
library(tidyr)
# sourcing the R script "HW2-dataframe-141B.R" which creates the overall data frame with 99958 lines, from the original log file
# each line of the log file is categorized into file name, date-time, logging host, app, PID and message columns representing these parts of each line of the log file
source("./HW2-dataframe-141B.R")
```


# Data Validation and Exploration

## 1. Checking if all PID values are numeric
```{r}
# finding if all values in PID columns are numeric (returns boolean)
numeric_pid <- all(grepl("^\\d+$", df$PID))
print(numeric_pid)
```
This check for if all the PID columns are numeric returns false, because there are missing PIDs in some lines.

## 2. Number of Lines in each log File
```{r}
# https://stackoverflow.com/questions/46017812/r-get-all-categories-in-column
# finding the number of lines that belong to each file
fname_counts <- table(df$logfilename)
print(fname_counts)
```
The table function is used to create a frequency table with the column in the data frame containing the file names that each line belongs to, and shows the number of lines that belong to each file. The printed table shows that auth.log file has 86839 lines, auth2.log has 7121 lines, loghub/Linux/Linux_2k.log has 1999 lines, loghub/Mac/Mac_2k.log has 1999 lines, and loghub/OpenSSH/SSH_2k.log has 2000 lines.

## 3. Finding Range of date-times for the Messages
```{r}
# range of dates for the entire file
first_date <- df$datetime[1]
end_date <- df$datetime[99958]
total_range <- difftime(end_date, first_date, units="days")
total_range
#finding the range of date-times for messages for each log file, and how many days the files span
# first datetime for auth.log
f1_firstDT <- df$datetime[1]
# last datetime for auth.log
f1_secDT <- df$datetime[86839]
f1_dayRange <- difftime(f1_secDT, f1_firstDT, units="days")
f1_dayRange

# day range for auth2.log
f2_start <- df$datetime[86840]
f2_end <- df$datetime[93960]
f2_dayRange <- difftime(f2_end, f2_start, units="days")
f2_dayRange

# day range for loghub/Linux/Linux_2k.log
f3_start <- df$datetime[93961]
f3_end <- df$datetime[95959]
f3_dayRange <- difftime(f3_end, f3_start, units="days")
f3_dayRange

# day range for loghub/Mac/Mac_2k.log
f4_start <- df$datetime[95960]
f4_end <- df$datetime[97958]
f4_dayRange <- difftime(f4_end, f4_start, units="days")
f4_dayRange

# day range for loghub/OpenSSH/SSH_2k.log
f5_start <- df$datetime[97959]
f5_end <- df$datetime[99958]
f5_dayRange <- difftime(f5_end, f5_start, units="days")
f5_dayRange
```

The first log file, auth.log, spans `r f1_dayRange`. The second log file, auth2.log, spans `r f2_dayRange`. The third log file, loghub/Linux/Linux_2k.log, spans `r f3_dayRange`. The fourth log file, loghub/Mac/Mac_2k.log, spans `r f4_dayRange`. The fifth log file, loghub/OpenSSH/SSH_2k.log, spans `r f5_dayRange`.

## 4. Checking if app Names Contain Numbers
```{r}
# do the app names contain numbers
# this function take a value from the app column in the df to determine if their are numbers in the name
search_appNums <- function(a){
  find_num <- regexpr("[0-9]+", a)
  num_app <- find_num[1]
  # -1 means no numbers present in an app name, otherwise there are numbers present
  if (num_app != -1){
    # if at least one digit present, "True" is added to list of num_present
    num_present <- "True"
  }else{
    # no digits present
    num_present <- "False"
  }
  num_present <- num_present
  # list of results for each app name returned
  return (num_present)
}
# applying search_appNums to every app value in the data frame
results <- apply(df[, "app", drop=FALSE], 1, search_appNums)
print(table(results))
```
There does not appear to be application names that contain numbers, as evident by the results of the frequency table above. The search_appNums() function was used and applied to every value in the app column of the data frame using the apply() function. search_appNums() takes each app names value and searches for the presence of any and all digits using regexpr(). If there appears to be at least one digit, a string "True" is added to a list called num_present, otherwise "False" is added to the list for each particular app value. The returned list of True and False values pertaining to each app name values inputted in the table() function as a parameter, to create a frequency table of "True" and "False" values, in order to see the number of apps with numbers in their names (True) and apps without numbers in their names (False). The frequency table showed that there were 99958 app values that resulted in "False." Since there are 99958 entries total in the data frame, that means there were no app values that have numbers in the app name (returned "True").

## 5. Are the Logging Hosts Constant in Each Log File?
```{r}
# finding if logging host names are constant in each log file by creating frequency table of logging host names
counts_hostname <- table(df$logginghost)
counts_hostname
```

The logging host value is evident to not be constant for all records in each log file, as seen by using the table() function, which took in the logginghost column of the data frame (df$logginghost) to create a frequency table grouping different logging host values within the logging host columns for the entire file, which displays 42 different logging host values, with four most common being combo, ip-10-77-20-248, ip-172-31-27-153, and LabSZ. ip-172-31-27-153 was used 86839 times, ip-10-77-20-248 was used 7121 times, combo 1999 times and LabSZ 2000 times.

## 6. Finding the Most Common Applications Used
```{r}
#finding the most common app manually by looking at frequencies of apps
app_counts <- table(df$app)
print(app_counts)
```
The table function is used to create a frequency table from the app column of the data frame, displaying the number of times each application appear to be logging information on each of the different hosts. By manually examining this frequency table, we can find the most common apps by identifying which applications have the highest frequency. It can be seen that the top three most common apps used were sshd (91341 usages), CRON (2857 usages), and ftpd (916 usages).


# Logins
## Valid Logins
```{r}
#https://stackoverflow.com/questions/2192316/extract-a-regular-expression-match 
# Valid logins
# finding all messages that say "Accepted publickey" indicating valid login
accepted_publickeys <- grepl("Accepted publickey for ", df$message)
#new_sessions <- grepl("New session ", df$message)
accepted_publickeys <- df[accepted_publickeys, ]
#new_sessions <- df[new_sessions, ]
# data frame containing valid logins - indicated by messages stating "accepted publickey" or "New session" for a user
valids_df <- rbind(accepted_publickeys)
print(valids_df)

# looping through every row in the data frame with valid logins (valids_df) extracting ip addresses of users from every valid login message
for(i in 1:36){
  ip_search <- regexpr("[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+", valids_df$message[i])
  ips_start <- ip_search[1]
  ips_len <- attr(ip_search, "match.length")
  # if the ip_search[1]==1 that means there is an ip address in the message
  if(ip_search[1] == 1){
    # substring of the message portion of the line to get ip address
    ip <- substr(valids_df$message[i],ips_start,ip_search+ips_len-1)
    ip <- ip
  }
  i = i+1
}
print(ip)
```

Valid logins were identified based on the message portion of the log file lines, specifically looking at lines with messages that began with "accepted publickey for" a user with an ip address. These lines were extracted from the larger data frame to create a data frame of the subsetted valid logins, named "valids_df". All these valid logins appear to have been made by the same user, "ubuntu" which was found through manual scan of the 36 valid logins, and the same ip address of `r ip` as well. The ip address was found by using regexpr to identify the ip address in the message of each line of the valid login data frame.


## Invalid Logins
```{r}
# Invalid Logins
# extracting all rows from df with messages that include "Invalid user" indicating invalid login
invalid_users <- grepl("Invalid user ", df$message)
invalid_users <- df[invalid_users, ]
# extracting all rows from df with messages that include "error: maximum authentication attempts exceeded for " indicating invalid login
max_attempts <- grepl("error: maximum authentication attempts exceeded for ", df$message)
max_attempts <- df[max_attempts, ]
# extracting all rows from df with messages that include "Too may authentication failures " indicating invalid login
auth_fails <- grepl("Too many authentication failures ", df$message)
auth_fails <- df[auth_fails, ]

# creating empty data frame to bind rows of invalid logins from the overall df found above
invalids_df <- data.frame()
# invalids_df containing rows with invalid logins
invalids_df <- rbind(invalids_df, invalid_users, max_attempts, auth_fails)
print(invalids_df)

# finding ip addresses associated with all invalid logins -> make into a new column in data frame -> use table to print frequencies for analysis
get_ip <- function(invalid_msg){
  ip_search <- regexpr("[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+", invalid_msg)
  ips_start <- ip_search[1]
  ips_len <- attr(ip_search, "match.length")
  # if the ip_search[1]==1 that means there is an ip address in the message
  if(ip_search[1] != 1){
    # substring of the message portion of the line to get ip address
    invalids_ip <- substr(invalid_msg,ips_start,ip_search+ips_len-1)
    invalids_ip <- invalids_ip
  }
  return (invalids_ip)
}

invalids_ips <- apply(invalids_df[, "message", drop=FALSE], 1, get_ip)
#converting list of ip addresses into data frame
invalids_ip_df <- data.frame(invalids_ips)
# adding as new column to data frame of invalid logins - ip addresses associated with each invalid login
invalids_df <- cbind(invalids_df, invalids_ip_df)
invalids_ip_table<- table(invalids_df$invalids_ips)
print("Frequency Table of IP Addresses Associated with Invalid Logins")
print(invalids_ip_table)
```
Invalid user logins were identified firstly based on keywords in the message columns of the original data frame, which included "Invalid user", "error: maximum authentication attempts exceeded for" and "Too many authentication failures." The rows in the data frame with messages containing these key phrases were extracted and added to a new data frame called invalids_df, to be a subset of the larger data frame, with all rows of invalid logins. The IP addresses of each invalid login/message were then extracted from each line through the creation and use of the get_ip() function, which takes a row of the messages column of the data frame to extract the ip address from the message string and add it to a list of ip addresses for the entire data frame. In the get_ip() function, regexpr() is used to look for the pattern of an ip address (four instances sequences of numbers separated by periods) followed by the substring() function separate what comes before and after the identified ip address, in order to get the ip address as a variable and add it to the list.
The apply() function is used to apply the get_ip() function to every message column of the invalids data frame. Once a list of all the ip addresses associated with every invalid login is acquired, the list was converted to a data frame, then added to the invalids_df data frame to become additional column that clearly displays the ip addresses for each row. The table() function was used to create a frequency table of the ip addresses, showing the number of times each ip address was used. 

The frequency table of the associated ip addresses above makes it evident that there were several invalid user logins from the same IP address, such as 61.197.203.243 with 409 appearances in invalid user login messages. This can also be seen by scrolling through the invalids_df data frame, onserving the ip addresses column, as there are several consecutive invalid user logins that were made from the same ip address, often near the same date and time as well, although at times the user name would vary despite the same ip address and invalid login message.

There does appear to have been valid logins from one IP address that appeared in the invalid logins data frame as well, which is 85.245.107.41. This is also the only IP address that was found to be associated with valid logins, as only logins with the message "Accepted publickey" were considered when examining the valid user logins, although there is possibility of other valid logins with different IP addresses associated as well. This IP address appeared in two invalid user logins with the message "Invalid user test from.." and Invalid user dale from .." thus being from two different users.

There is no ip address associated with the invalid user login that had the message "Too many authentication failures," which can be seen by the blank spaces next the these rows in the ip address column of the data frame. The message column for these messages displays the user "root" being the same for all these particular invalid user logins, however there is no ip address like the other messages.


# Sudo Commands
```{r}
# Executables run by sudo
# creating data frame for sudo programs
# USER="" is user, COMMAND="" is the executable
sudo_lines <- grepl("USER=", df$message)
sudo_lines <- df[sudo_lines, ]
sudos_df <- data.frame()
sudos_df <- rbind(sudo_lines)
print(sudos_df)
# function that will search through the message column of the sudo dataframe and subset the username based on what comes after "USER=" in the message
find_users <- function(line){
  user_search <- regexpr("USER=", line)
  # if the "USER=" is in the message portion of the data frame the function continues to subset the string to find the name of the user
  if (user_search[1] != -1){
    # the cutoff_point is the point where the "USER=" ends/where the user name begins 
    cutoff_point <- user_search[1] + attr(user_search, "match.length")
    # take substring of the message string where the string is from the user name start to the end of the message string
    sub <- substring(line, cutoff_point, nchar(line))
    # the name of the user is found as all the users in the message of each line ends with a space
    user <- substr(sub, 1, regexpr(" ", sub)-1)
    # adding the user of this line to list of users
    user <- user
  }
  # return list of user names
  return (user)
}
# function that will search through the message column of the sudo dataframe and subset the executable/program based on what comes after "COMMAND=" in the message
find_programs <- function(line){
  command_search <- regexpr("COMMAND=", line)
  # if the "COMMAND=" is in the message portion of the data frame the function continues to subset the string to find the executable/program
  if(command_search[1] != -1){
    # the cutoff_point is the point where the "COMMAND=" ends or where the executable begins 
    cutoff_point <- command_search[1] + attr(command_search, "match.length")
    # take substring of the message string where the string is from the executable start to the end of the message string
    sub <- substring(line, cutoff_point, nchar(line))
    # the executable either ends with hyphen, space or no space so final substring is taken where the executable is identified
    sudo_program <- substr(sub, 1, regexpr("-", sub)-1)
    sudo_program <- substr(sub, 1, regexpr("", sub)-1)
    sudo_program <- substr(sub, 1, regexpr(" ", sub)-1)
    # adding sudo program of this line to list of sudo programs
    sudo_program <- sudo_program
  }
  # return a list of sudo programs
  return (sudo_program)
}
# applying find_users function to each message column of each row in the sudos data frame
sudo_users <- apply(sudos_df[, "message", drop=FALSE], 1, find_users)
print("List of Users for all Sudo")
print(sudo_users)
print()
# applying find_programs function to each message column of each row in the sudos data frame
sudo_programs <- apply(sudos_df[, "message", drop=FALSE], 1, find_programs)
print("All Sudo Executables")
print(sudo_programs)
print()

# What machines are used - creating frequency table showing frequency of each logginghost 
sudo_machines <- table(sudos_df$logginghost)
print("Machines used for executables via Sudo")
print(sudos_machines)
```
To find the executables/programs run via sudo as well as user names, the first step was extracting the lines from the log file with the app sudo from the overall data frame and creating a subset data frame with just sudo lines. Two functions were created to find the executables and users for the sudo lines. The user_search function takes a line from the sudo data frame and uses regexpr() to find the index of "USER=" in the "message" portion, because this is followed by the user. The substring() function is used to subset the message to all elements after the index where the "=" appears in "USER=", which is where the user begins. There is a space after the name of the user so it is found to be at the beginning of this subset of the message string. The apply function is used to apply the user_search() function to all lines in the message column of the sudos_df data frame and return a list of all the names of the users. The first list above, of users, shows that the user is the same for all the executables run via sudo, "root."

Similarly, to find the executables, the find_programs() function is used, which takes a line from the sudos data frame and uses regexpr() to find the index of "COMMAND=" in the "message" portion, because this is followed by the executable. The substring() function is again used to take a substring of the message portion of the line, where the executable is the start of the string. The end of the executable is either a hyphen, space or no space, and these conditions are used to find the executables of each line in the sudos data frame. There are a variety of executables in the sudos data frame, as seen in the second list above.

All users that are running a program via sudo are on the same machine, which was found using the table() function to create a frequency table that shows the frequency of each different logging host in the logginghost column of the sudos data frame. Since the result was the single machine, `r sudos_machines`.


